---
title: "Deconvolution Algorithm Comparison"
output: 
   html_document:
      toc: true
      toc_float:
         collapsed: true
         smooth_scroll: true
params:
   tempdir: ""
   metric: "cor"
   metric.name: ""
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
temp.dir <- params$tempdir
plot.dir <- paste(temp.dir, "report_plots", sep = '/')
if(!dir.exists(plot.dir)){
  dir.create(plot.dir)
}
metric <- params$metric
metric.name <- params$metric.name
if(is.character(metric)){
    if(metric != "cor"){
        stop("metric must be either \"cor\" or a function")
    }else{
		if(is.null(metric.name) || !is.character(metric.name)){
				metric.name <- "custom metric"
			}
        metric <- cor
    }
}else{
	if(!is.function(metric)){
		stop("Function corresponding to 'metric' could not be found.")
	}else{
		if(is.null(metric.name) || !is.character(metric.name)){
				metric.name <- "custom metric"
			}
	}
}
	
benchmark.name <- strsplit(temp.dir, "/")[[1]][length(strsplit(temp.dir, "/")[[1]])]
# read input and processed data
input_raw <- read_data(paste(temp.dir, "/input_data/raw.h5", sep=""))
sc.counts <- input_raw$sc.counts
sc.pheno <- input_raw$sc.pheno
real.counts <- input_raw$bulk.counts
real.props <- input_raw$bulk.props
validation_set <- read_data(paste(temp.dir, "/input_data/validation_set.h5", sep = ""))
training_set <- read_data(paste(temp.dir, "/input_data/training_set.h5", sep=""))
training.exprs <- training_set$sc.counts
training.pheno <- training_set$sc.pheno
test.exprs <- validation_set$sc.counts
test.pheno <- validation_set$sc.pheno
sim.bulks <- list(bulks = validation_set$real.counts, props = validation_set$real.props)
# load input parameters
input_params <- read_misc_input(paste(temp.dir, "input_data/params.h5", sep = "/"))
genesets <- input_params$genesets
algorithm.names <- input_params$algorithms
function.call <- input_params$function.call
grouping <- input_params$grouping
```

# Deconvolution Benchmark

## Input data
<button  type="button"
   onclick="if(document.getElementById('input') .style.display=='none')
              {document.getElementById('input') .style.display=''}
            else{document.getElementById('input') .style.display='none'}">
  Show/hide
</button>
<div id="input" style="display:none" >
Parameters of the `benchmark` call:
```{r}
function.call.list <- as.list(function.call)

adjusted.names <- sapply(
  X = names(function.call.list)
  , FUN = function(x){if(x != ""){return(paste0(x, " ="))}else{return(x)}}
  , USE.NAMES = FALSE
  )
print(paste(adjusted.names, function.call.list)) 
``` 

Single-cell data contained `r nrow(sc.counts)` features for `r ncol(sc.counts)` cells.  


Corresponding phenotype data contained labels for `r length(unique(sc.pheno$cell_type))` cell types: 
```{r}
  t <- table(sc.pheno$cell_type)
  print(paste(names(t), t, sep = ": "))
```


Used algorithms: `r algorithm.names`   


`r ncol(real.counts)` real bulk profiles were available, with `r length(intersect(rownames(real.counts), rownames(sc.counts)))` overlapping features

Ground-truth cell type quantities were available for `r nrow(real.props)` cell types.  


```{r real_props, echo = FALSE}
  print(t(apply(real.props, 1, summary)))
```
\pagebreak
</div>
## Deconvolution of real bulks  

```{r real_results, echo=FALSE}
  files <- list.files(paste(temp.dir, "/results/real", sep = ""), full.names = T, pattern = "deconv.*.h5")
  results.lists <- list()
  if(length(files) > 0){
  for(i in 1:length(files)) {
    results.lists[[i]] <- read_result_list(files[i])
  }
  
  for(i in 1:length(results.lists)){
  	temp.df <- prepare_data(results.lists[[i]], metric, metric.name)
  	if(!is.null(temp.df)){
  		if(!exists("real.df")){
  			real.df <- temp.df
  		}else{
  			real.df <- rbind(real.df, temp.df)
   		}
  	}
  }
  
  files <- list.files(paste(temp.dir, "/results/real", sep = ""), full.names = T, pattern = "bootstrap.*.h5")
  if(length(files) > 0){
    bootstrap.data <- c()
    for(f in files) {
	  temp <- h5_read_mat(f)
      bootstrap.data <- rbind(bootstrap.data, temp)
    }
    bootstrap.data <- as.data.frame(bootstrap.data)
    bootstrap.data$score <- as.numeric(as.character(bootstrap.data$score))
    
    bootstrap.plot.width <- length(unique(bootstrap.data$algorithm)) * 2
    bootstrap.plot.height <- length(unique(bootstrap.data$cell_type)) * 2
  }

  score.plot.list <- evaluation_plot(real.df, "deconvolution quality", metric, metric.name)
  score.plot <- score.plot.list$plot
  celltypes.ordered <- score.plot.list$celltype.order
  algorithms.ordered <- score.plot.list$algorithm.order
  
  runtime.plot <- plot_runtime(real.df, algorithm.order = algorithms.ordered)
  scatter.plots.list <- list()
  for(i in 1:length(results.lists)) {
  	scatter.plots.list[[i]] <- create_scatterplots(results.lists[[i]], celltype.order = celltypes.ordered, algorithm.order = algorithms.ordered)
  }
  cond.num.plots <- plot_cond_num(real.df, metric = metric, metric.name = metric.name, algorithm.order = algorithms.ordered)
  
  score.width <- 2 * length(unique(real.df$cell_type))
  score.height <- 2 * length(algorithm.names)
  }else{
	  score.width = 1
	  score.height = 1
	  bootstrap.plot.width <- 1
	  bootstrap.plot.height <- 1
  }
```

### Score plot
```{r score_plot, echo = FALSE, fig.width = score.width, fig.height = score.height}
if(exists("score.plot")){
	plot(score.plot)
	pdf(paste(plot.dir, "score_plot_real.pdf", sep = "/"), width = score.width, height = score.height)
	plot(score.plot)
	invisible(dev.off())
}
```  

Deconvolution result for real bulks per algorithm and cell type. The value is the pearson correlation coefficient, coded by rectangle size and color (small to big, red to green with increasing performance). Negative and undefined correlations were set to 0. The overall column contains the average performance of the algorithm across all cell types.
In case of multiple repetitions, the plotted scores are averages over all repetitions. The pearson r specified for each algorithm corresponds to the 'overall' column. Uncertainty (standard deviation) of the overall performance is specified for each algorithm as well.
\pagebreak  

### Scatter plots of quantities
```{r scatter_plots, echo = FALSE, fig.width = 18, fig.height = 5}
if(exists("scatter.plots.list")){
for(l in scatter.plots.list){
	if(!is.null(l)){
		for(p in l){
			if(!is.null(p))
				plot(p)
			}
	}
}
pdf(paste(plot.dir, "scatter_plots_real.pdf", sep = "/"), width = 18, height = 5)
for(l in scatter.plots.list){
	if(!is.null(l)){
		for(p in l){
			if(!is.null(p))
				plot(p)
			}
	}
}
invisible(dev.off())
}
```  

Comparison of the real cell type quantities and the estimated quantities per cell type for each algorithm. 
\pagebreak  

### Runtime plot
```{r runtime_plot, echo = FALSE, fig.width = 16, fig.height = 9}
if(exists("runtime.plot")){
	plot(runtime.plot)
	pdf(paste(plot.dir, "runtime_plot_real.pdf", sep = "/"), width = 16, height = 9)
	plot(runtime.plot)
	invisible(dev.off())
}
```  
  
Runtime per algorithm. Due to possible large differences in runtime the scale on the y-axis is transformed using the log10. In case of multiple repetitions, the plotted runtimes are averages over all repetitions.
\pagebreak  

### Additional Plots
<button  type="button"
   onclick="if(document.getElementById('additional_info') .style.display=='none')
              {document.getElementById('additional_info') .style.display=''}
            else{document.getElementById('additional_info') .style.display='none'}">
  Show/hide
</button>
<div id="additional_info" style="display:none" >
### Condition number plots
```{r condition_plots, fig.width = 16, fig.height = 9}
if(exists("cond.num.plots")){
plot(cond.num.plots$cond_num_plot)  

plot(cond.num.plots$cond_vs_score)  

plot(cond.num.plots$variation_plot)

pdf(paste(plot.dir, "condition_number_plots_real.pdf", sep = "/"), width = 16, height = 9)
plot(cond.num.plots$cond_num_plot)  

plot(cond.num.plots$cond_vs_score)  

plot(cond.num.plots$variation_plot)
invisible(dev.off())
}
```  
  

1) Average condition numbers of the reference matrices produced by different algorithms (models).  
  
2) Dependency of score (average overall pearson correlation) on condition number of the model  
  
3) Standard deviation of the score (correlation) of the model across multiple repetitions depending on the variability of the model's condition number

### Bootstrapped Bulks
```{r bootstrap_plots, fig.width = bootstrap.plot.width, fig.height = bootstrap.plot.height}
if(exists("bootstrap.data")){
  bootstrap.plot <- ggplot2::ggplot(bootstrap.data, aes(x = algorithm, y = score, col = algorithm)) + facet_grid(rows = vars(cell_type)) + geom_boxplot() + ylim(0,1)
  plot(bootstrap.plot)
  pdf(paste(plot.dir, "bootstrap_plot_real.pdf", sep = "/"), width = bootstrap.plot.width, height = bootstrap.plot.height)
  plot(bootstrap.plot)
  invisible(dev.off())
}
```
</div>
  
\pagebreak

## Simulations
```{r simulation_results, echo = FALSE}
# bulk benchmark
if(dir.exists(paste(temp.dir, "/results/simulation/bulks", sep = ""))) {
	results.lists <- list()
	files <- list.files(paste(temp.dir,"/results/simulation/bulks", sep=""), full.names = T, pattern = "*.h5")
	if(length(files) > 0){
		for(i in 1:length(files)){
			results.lists[[i]] <- read_result_list(files[i])
		}
		bulks.df <- data.frame()
		for(i in 1:length(results.lists)){
			bulks.df <- rbind(bulks.df, prepare_data(results.lists[[i]], metric, metric.name))
		}

		score.plot.sim.list <- evaluation_plot(bulks.df, "deconvolution quality (simulated bulks)", metric, metric.name)
		
		score.plot.sim <- score.plot.sim.list$plot
		algorithms.ordered <- score.plot.sim.list$algorithm.order
		celltypes.ordered <- score.plot.sim.list$celltype.order
	
		runtime.plot.sim <- plot_runtime(bulks.df, algorithm.order = algorithms.ordered)
		scatter.plots.list.sim <- list()
		for(i in 1:length(results.lists)){
			scatter.plots.list.sim[[i]] <- create_scatterplots(results.lists[[i]], celltype.order = celltypes.ordered, algorithm.order = algorithms.ordered)
		}
		score.width <- 2*length(unique(bulks.df$cell_type))
		score.height <- 2 * length(unique(bulks.df$algorithm))
	}
}else{
  algorithms.ordered = NULL
  celltypes.ordered = NULL
}
# sample benchmark
if(dir.exists(paste(temp.dir, "/results/simulation/samples", sep = ""))){
	results.lists <- list()
	files <- list.files(paste(temp.dir, "/results/simulation/samples", sep = ""), full.names = T, pattern = "*.h5")
	if(length(files) > 0){
		for(i in 1:length(files)){
			results.lists[[i]] <- read_result_list(files[i])
		}
		samples.df <- data.frame()
		for(i in 1:length(results.lists)){
			samples.df <- rbind(samples.df, prepare_data(results.lists[[i]], metric, metric.name))
		}
		sample.plots <- create_boxplots(samples.df, metric = metric, metric.name = metric.name, celltype.order = celltypes.ordered, algorithm.order = algorithms.ordered)
	}
}

# gene benchmark
if(dir.exists(paste(temp.dir, "/results/simulation/genes", sep=""))){
	results.lists <- list()
	files <- list.files(paste(temp.dir, "/results/simulation/genes/", sep=""), full.names = T, pattern = "*.h5")
	if(length(files) > 0){
		for(i in 1:length(files)){
			results.lists[[i]] <- read_result_list(files[i])
		}
		genes.df <- data.frame()
		for(i in 1:length(results.lists)){
			genes.df <- rbind(genes.df, prepare_data(results.lists[[i]], metric, metric.name))
		}
		gene.plots <- create_lineplots(genes.df, metric = metric, metric.name, genesets, rownames(training.exprs), algorithm.order = algorithms.ordered, celltype.order = celltypes.ordered)
	}
}

# subtype benchmark
if(dir.exists(paste(temp.dir, "/results/simulation/subtypes", sep=""))){
	results.lists <- list()
	files <- list.files(paste(temp.dir, "/results/simulation/subtypes/", sep=""), full.names = T, pattern = "*.h5")
	if(length(files) > 0){
		for(i in 1:length(files)){
			results.lists[[i]] <- read_result_list(files[i])
		}
		subtypes.df <- data.frame()
		for(i in 1:length(results.lists)){
			subtypes.df <- rbind(subtypes.df, prepare_data(results.lists[[i]], metric, metric.name))
		}
		score.plot.subtype <- subtype_plot(subtypes.df)
		#runtime.plot.subtype <- plot_runtime(subtypes.df, algorithm.order = algorithms.ordered)
	}
}
```

### Bulk simulations
### Score plot
```{r bulk_sim_scores, fig.width = score.width, fig.height = score.height}
if(exists("score.plot.sim")){
	plot(score.plot.sim)
  pdf(paste(plot.dir, "score_plot_simulated.pdf", sep = "/"), width = score.width, height = score.height)
  plot(score.plot.sim)
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  
  
Deconvolution result for simulated bulks per algorithm and cell type. The value is the pearson correlation coefficient, coded by rectangle size and color (small to big, red to green with increasing performance). Negative and undefined correlations were set to 0. The overall column contains the average performance of the algorithm across all cell types.
In case of multiple repetitions, the plotted scores are averages over all repetitions. The pearson r specified for each algorithm corresponds to the 'overall' column. Uncertainty (standard deviation) of the overall performance is specified for each algorithm as well.  
Bulks were simulated by adding up a fixed number of randomly sampled single-cell profiles.
\pagebreak

### Scatter plot of quantities
```{r bulk_sim_scatter, fig.width = 18, fig.height = 5}
if(exists("scatter.plots.list.sim")){
	for(l in scatter.plots.list.sim){
		for(p in l){
			plot(p)
		}
	}
  pdf(paste(plot.dir, "scatter_plots_simulated.pdf", sep = "/"), width = 18, height = 5)
	for(l in scatter.plots.list.sim){
		for(p in l){
			plot(p)
		}
	}
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  

Comparison of the real cell type quantities (in the simulated bulks) and the estimated quantities per cell type for each algorithm. Only the results of the first repetition are shown.

\pagebreak
### Training set size simulation
### Score boxplots
```{r sample_sim, fig.width = 16, fig.height = 9}
if(exists("sample.plots")){
	for(p in sample.plots$cell.type.plots) plot(p)
  pdf(paste(plot.dir, "sample_plots_simulated.pdf", sep = "/"), width = 16, height = 9)
  for(p in sample.plots$cell.type.plots) plot(p)
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  

Variability of performance of algorithms using different amounts and selection of training data for learning and reference profile creation. The score is the average correlation across multiple repetitions (if number of repetitions greater than 1). Overall denotes the average correlation coefficient of all cell types. Bulks used for deconvolution were simulated by adding up a fixed number of randomly sampled expression profiles.

\pagebreak
### Geneset simulation

### Runtime lineplot
```{r geneset_sim_time, fig.width = 16, fig.height = 9}
if(exists("gene.plots")){
	plot(gene.plots$runtime.plot)
  
  pdf(paste(plot.dir, "gene_time_plot_simulated.pdf", sep = "/"), width = 16, height = 9)
  plot(score.plot.sim)
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  
  
Runtime of algorithms depending on the gene set supplied for deconvolution. Each algorithm performed a separate feature selection on the gene set to obtain the features used in the model. Gene sets are ordered by the size of the intersect of features available in the gene set and the single-cell data.

### Score lineplots
```{r geneset_sim, fig.width = 16, fig.height = 9}
if(exists("gene.plots")){
	for(p in gene.plots$cell.type.plots)
		plot(p)
  pdf(paste(plot.dir, "gene_score_plots_simulated.pdf", sep = "/"), width = 16, height = 9)
	for(p in gene.plots$cell.type.plots)
		plot(p)
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  

Performance of algorithms depending ont the gene set supplied for deconvolution. Each algorithm performed a separate feature selection on the gene set to obtain the features used in the model. Gene sets are ordered by the size of the intersect of features available in the gene set and the single-cell data. Score is the pearson correlation averaged of multiple repetitions. Errorbars show standard deviation of the score across repetitions.

\pagebreak

### Subtype simulation
### Score plot
```{r subtype_sim, fig.width = score.width, fig.height = score.height}
if(exists("score.plot.subtype")){
  #plot(score.plot.subtype$overall)
  #plot(score.plot.subtype$algorithm)
  plot(score.plot.subtype$coarse)
  pdf(paste(plot.dir, "subtype_plot.pdf", sep = "/"), width = score.width, height = score.height)
  #plot(score.plot.subtype$overall)
  #plot(score.plot.subtype$algorithm)
  plot(score.plot.subtype$coarse)
  invisible(dev.off())
}else{
	cat("No data available for plotting.\n")
}
```  
  
Deconvolution result for simulated bulks per algorithm and cell type. The value is the pearson correlation coefficient, coded by rectangle size and color (small to big, red to green with increasing performance). Negative and undefined correlations were set to 0. The overall column contains the average performance of the algorithm across all cell types.
In case of multiple repetitions, the plotted scores are averages over all repetitions. The pearson r specified for each algorithm corresponds to the 'overall' column. Uncertainty (standard deviation) of the overall performance is specified for each algorithm as well.  
Bulks were simulated by adding up a fixed number of randomly sampled single-cell profiles.  
For each cell type, a fixed number of subtypes was simulated based on t-SNE embedding and unsupervised clustering. Deconvoution was performed with a reference profile for each subtype and the estimated quantities of all subtypes of the same cell type were added to arrive at the final estimation for each cell type.
<!--\pagebreak
<!-- ### Runtime plot -->
<!-- ```{r, fig.width = 16, fig.height = 9} -->
<!-- if(exists("runtime.plot.subtype")){ -->
<!--   plot(runtime.plot.subtype) -->
<!--   pdf(paste(plot.dir, "subtype_plot_runtime.pdf", sep = "/"), width = 16, height = 9) -->
<!--   plot(runtime.plot.subtype) -->
<!--   invisible(dev.off()) -->
<!-- }else{ -->
<!-- 	cat("No data available for plotting.\n") -->
<!-- } -->
<!-- ``` -->
