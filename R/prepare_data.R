#' prepare_data
#'
#' @param results.all list of lists, as generated by the 'benchmark()' function
#' @param metric evaluation metric; either string 'cor' (default) or a function
#' @param metric.name string, name of the evaluation metric used; not needed if metric is a string ("cor"). If metric is a function and metric.name
#' is NULL, the default will be "custom metric"
#' @return data frame containing information about every deconvolution result in the dataset
#' @export

prepare_data <- function(results.all, metric="cor", metric.name = NULL) {
    # parameter check
    # however, if results.all is not a list as written to file by 'benchmark'
    # the function will fail
    if(is.character(metric)){
    if(metric != "cor"){
			stop("metric must be either \"cor\" or a function")
		}else{
            if(is.null(metric.name) || !is.character(metric.name)){
				metric.name <- "custom metric"
			}
			metric <- cor
		}
  }else{
    if(!is.function(metric)){
			stop("Function corresponding to 'metric' could not be found.")
		}else{
            if(is.null(metric.name) || !is.character(metric.name)){
				metric.name <- "custom metric"
			}
        }
  }
    if(!is.list(results.all)){
        stop("results.all must be a list of lists that were returned by deconvolute or one of the simulation functions")
    }
    
    df <- c()

    # cases sample/geneset/bulk simulation
    if("bulk.props" %in% names(results.all)){

    # extract real proportions from lists
        real.props <- results.all$bulk.props
        results.list <- results.all[-which(names(results.all) == "bulk.props")]
        if(length(results.list) == 1) results.list <- results.list[[1]]

        # iterate through the results list
        # depth of the list depends on the benchmark
        for(i in 1:length(results.list)) {
            results <- results.list[[i]]
            for(res in results) {
                # if the list has three levels the top level represents the geneset or amount of samples used
                # if res contains lists, it is either geneset or sample benchmark
                if(is.list(res[[1]])) {
                    for(r in res) {
                        scores <- c()
                        name <- r$name
                        time <- as.numeric(r$times)

                        # try to determine what information is present in the lists
                        if(any(is.na(as.numeric(names(results.list)[i])))) {
                            geneset <- names(results.list)[i]
                            fraction <- 100
                        }else{
                            geneset <- NA
                            fraction <- as.numeric(names(results.list)[i])
                        }

                        # calculate condition number if reference is available
                        if(!is.null(r$sig.matrix)) {
                            cond.num <- kappa(r$sig.matrix, exact = T)
                        }else{
                            cond.num <- NA
                        }
                
                        # if the deconvolution worked evaluate according to given metric
                        if(!all(is.null(r$est.props)) && !all(is.na(r$est.props))){
                            # performance per cell type
                            for (t in intersect(rownames(r$est.props), rownames(real.props))) {
                                temp.score <- metric(r$est.props[t,], real.props[t,])
                                if(is.na(temp.score) || temp.score < 0){
                                    temp.score <- 0
                                }
                                scores <- c(scores, temp.score)
                                df <- rbind(df, c(name, temp.score, t, geneset, metric.name, time, fraction, cond.num))
                            }
                            # overall performance (average over per-cell-type-performance); store as cell type "overall"
                            df <- rbind(df, c(name, mean(scores), "overall", geneset, metric.name, time, fraction, cond.num))
                        }else{
                            df <- rbind(df, c(name, 0, "overall", geneset, metric.name, time, fraction, cond.num))
                        }
                    }
                }else{
                    # this is executed if the list has two levels -> bulk benchmark
                    # this is actually the same as above, only with fixed values for fraction and gene set
                    # would be more elegant to join both cases but it works for now
                    scores <- c()
                    r <- res
                    name <- r$name
                    time <- as.numeric(r$times)
                    # calculate condition number if reference is available
                    if(!is.null(r$sig.matrix)) {
                        cond.num <- kappa(r$sig.matrix, exact = T)
                    }else{
                        cond.num <- NA
                    }
                    # if the deconvolution worked evaluate according to given metric
                    if(!all(is.null(r$est.props)) && !all(is.na(r$est.props))){
                        # performance per cell type
                        for (t in intersect(rownames(r$est.props), rownames(real.props))) {
                            temp.score <- metric(r$est.props[t,], real.props[t,])
                            if(is.na(temp.score) || temp.score < 0){
                                    temp.score <- 0
                            }
                            scores <- c(scores, temp.score)
                            df <- rbind(df, c(name, temp.score, t, NA, metric.name, time, 100, cond.num))
                        }
                        # overall performance
                        df <- rbind(df, c(name, mean(scores), "overall", NA, metric.name, time, 100, cond.num))
                    }else{
                            df <- rbind(df, c(name, 0, "overall", NA, metric.name, time, 100, cond.num))
                    }
                }
            }
        }
    df <- as.data.frame(df)
    # if a column is missing, something was wrong with the data
    if(ncol(df) != 8) 
	    return(data.frame())
    colnames(df) <- c("algorithm", "score", "cell_type", "geneset", "metric", "time", "fraction", "condition_number")
    df$score <- as.numeric(as.character(df$score))
    df$time <- as.numeric(as.character(df$time))
    df$condition_number <- as.numeric(as.character(df$condition_number))
    df$fraction <- as.numeric(as.character(df$fraction))
    }else{
        if(all(grepl("subtype.avg", names(results.all), fixed = TRUE))){
            # case subtype benchmark
            for(subtype.column in names(results.all)){
                results.list <- results.all[[subtype.column]]
                avg.cells <- as.numeric(strsplit(subtype.column, ".", fixed = TRUE)[[1]][3])
            
            c.true <- results.list[["c.true"]]
            c.true.coarse <- results.list[["c.true.coarsly"]]

            c.est.list <- results.list[["c.estimated.list"]]
            c.est.list.coarse <- results.list[["c.estimated.coarsly.list"]]


            # fine cell types
            for(a in names(c.est.list)){
                a.est <- c.est.list[[a]]
                coarse <- FALSE
                scores <- c()
                if(!is.null(a.est)){
                    for(t in intersect(rownames(a.est), rownames(c.true))){
                        temp.score <- metric(a.est[t,], c.true[t,])
                        if(is.na(temp.score) || temp.score < 0){
                            temp.score <- 0
                        }
                        scores <- c(scores, temp.score)
                        df <- rbind(df, c(a, temp.score, t, NA, metric.name, NA, NA, NA, coarse, avg.cells))
                    }
                    df <- rbind(df, c(a, mean(scores), "overall", NA, metric.name, NA, NA, NA, coarse, avg.cells))
                }else{
                    df <- rbind(df, c(a, 0, "overall", NA, metric.name, NA, NA, NA, coarse, avg.cells))
                }
            }

            # aggregated cell types (coarse)
            for(a in names(c.est.list.coarse)){
                a.est <- c.est.list.coarse[[a]]
                coarse <- TRUE
                scores <- c()
                if(!is.null(a.est)){
                    for(t in intersect(rownames(a.est), rownames(c.true.coarse))){
                        temp.score <- metric(a.est[t,], c.true.coarse[t,])
                        if(is.na(temp.score) || temp.score < 0){
                            temp.score <- 0
                        }
                        scores <- c(scores, temp.score)
                        df <- rbind(df, c(a, temp.score, t, NA, metric.name, NA, NA, NA, coarse, avg.cells))
                    }
                    df <- rbind(df, c(a, mean(scores), "overall", NA, metric.name, NA, NA, NA, coarse, avg.cells))
                }else{
                    df <- rbind(df, c(a, 0, "overall", NA, metric.name, NA, NA, NA, coarse, avg.cells))
                }
            }
            }
        
        df <- as.data.frame(df)
        # if a column is missing, something was wrong with the data
        if(ncol(df) != 10) 
            return(data.frame())
        colnames(df) <- c("algorithm", "score", "cell_type", "geneset", "metric", "time", "fraction", "condition_number", "coarse", "cluster_size")
        df$score <- as.numeric(as.character(df$score))
        df$time <- as.numeric(as.character(df$time))
        df$condition_number <- as.numeric(as.character(df$condition_number))
        df$fraction <- as.numeric(as.character(df$fraction))
        df$coarse <- as.logical(as.character(df$coarse))
        df$cluster_size <- as.numeric(as.character(df$cluster_size))
        }
    }
    return(df)
}
