#' prepare_data
#'
#' @param results.all list of lists, as generated by the 'benchmark()' function
#' @param metric string, must match one of 'c("cor", "mad", "rmsd")'
#' @return data frame containing information about every deconvolution result in the dataset
#' 
prepare_data <- function(results.all, metric="cor") {
    # parameter check
    # however, if results.all is not a list as written to file by 'benchmark'
    # the function will fail
    if(!metric %in% c("cor", "mad", "rmsd")){
        stop("Invalid metric. Must be one of 'cor', 'mad', 'rmsd'")
    }
    if(!is.list(results.all)){
        stop("results.all must be a list of lists that were returned by deconvolute or one of the simulation functions")
    }
    
    df <- c()
    # extract real proportions from lists
    real.props <- results.all$bulk.props
    results.list <- results.all[-which(names(results.all) == "bulk.props")]
    if(length(results.list) == 1) results.list <- results.list[[1]]

    # iterate through the results list
    # depth of the list depends on the benchmark
    for(i in 1:length(results.list)) {
        results <- results.list[[i]]
        for(res in results) {
            # if the list has three levels the top level represents the geneset or amount of samples used
            # if res contains lists, it is either geneset or sample benchmark
            if(is.list(res[[1]])) {
                for(r in res) {
                    scores <- c()
                    name <- r$name
                    time <- as.numeric(r$times)

                    # try to determine what information is present in the lists
                    if(any(is.na(as.numeric(names(results.list)[i])))) {
                        geneset <- names(results.list)[i]
                        fraction <- 100
                    }else{
                        geneset <- NA
                        fraction <- as.numeric(names(results.list)[i])
                    }

                    # calculate condition number if reference is available
                    if(!is.null(r$sig.matrix)) {
                        cond.num <- kappa(r$sig.matrix, exact = T)
                    }else{
                        cond.num <- NA
                    }
		    
                    # if the deconvolution worked evaluate according to given metric
                    if(!all(is.null(r$est.props)) && !all(is.na(r$est.props))){
                        # performance per cell type
                        for (t in intersect(rownames(r$est.props), rownames(real.props))) {
                            temp.score <- evaluate_deconvolution(r$est.props[t,], real.props[t,])[[metric]]
                            scores <- c(scores, temp.score)
                            df <- rbind(df, c(name, temp.score, t, geneset, metric, time, fraction, cond.num))
                        }
                        if(any(is.na(scores))) {
                            if(metric == "cor")
                                scores[is.na(scores)] <- 0
                        }
                        # overall performance (average over per-cell-type-performance); store as cell type "overall"
                        df <- rbind(df, c(name, mean(scores), "overall", geneset, metric, time, fraction, cond.num))
                    }
                }
            }else{
                # this is executed if the list has two levels -> bulk benchmark
                # this is actually the same as above, only with fixed values for fraction and gene set
                # would be more elegant to join both cases but it works for now
                scores <- c()
                r <- res
                name <- r$name
                time <- as.numeric(r$times)
                # calculate condition number if reference is available
                if(!is.null(r$sig.matrix)) {
                    cond.num <- kappa(r$sig.matrix, exact = T)
                }else{
                    cond.num <- NA
                }
                # if the deconvolution worked evaluate according to given metric
                if(!all(is.null(r$est.props)) && !all(is.na(r$est.props))){
                    # performance per cell type
                    for (t in intersect(rownames(r$est.props), rownames(real.props))) {
                        temp.score <- evaluate_deconvolution(r$est.props[t,], real.props[t,])[[metric]]
                        scores <- c(scores, temp.score)
                        df <- rbind(df, c(name, temp.score, t, NA, metric, time, 100, cond.num))
                    }
                    if(any(is.na(scores))) {
                            if(metric == "cor")
                                scores[is.na(scores)] <- 0
                        }
                    # overall performance
                    df <- rbind(df, c(name, mean(scores), "overall", NA, metric, time, 100, cond.num))
                }
            }
        }
    }
    df <- as.data.frame(df)
    # if a column is missing, something was wrong with the data
    if(ncol(df) != 8) 
	    return(data.frame())
    colnames(df) <- c("algorithm", "score", "cell_type", "geneset", "metric", "time", "fraction", "condition_number")
    df$score <- as.numeric(as.character(df$score))
    df$time <- as.numeric(as.character(df$time))
    df$condition_number <- as.numeric(as.character(df$condition_number))
    df$fraction <- as.numeric(as.character(df$fraction))
    return(df)
}
